{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from models import LorentzNet\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import json, time\n",
    "import utils\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 100\n",
    "epochs = 10\n",
    "val_interval = 1\n",
    "logdir = './logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(epoch, loader, partition):\n",
    "    if partition == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    res = {'time':0, 'correct':0, 'loss': 0, 'counter': 0, 'acc': 0,\n",
    "           'loss_arr':[], 'correct_arr':[],'label':[],'score':[]}\n",
    "\n",
    "    tik = time.time()\n",
    "    loader_length = len(loader)\n",
    "\n",
    "    for i, (label, p4s, nodes, atom_mask, edge_mask, edges) in enumerate(loader):\n",
    "        if partition == 'train':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_size, n_nodes, _ = p4s.size()\n",
    "        atom_positions = p4s.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device)\n",
    "        edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device)\n",
    "        nodes = nodes.view(batch_size * n_nodes, -1).to(device,dtype)\n",
    "        edges = [a.to(device) for a in edges]\n",
    "        label = label.to(device, dtype).long()\n",
    "\n",
    "        pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                         edge_mask=edge_mask, n_nodes=n_nodes)\n",
    "        \n",
    "        predict = pred.max(1).indices\n",
    "        correct = torch.sum(predict == label).item()\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        if partition == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif partition == 'test':\n",
    "            # save labels and probilities for ROC / AUC\n",
    "            score = torch.nn.functional.softmax(pred, dim = -1)\n",
    "            res['label'].append(label)\n",
    "            res['score'].append(score)\n",
    "\n",
    "        res['time'] = time.time() - tik\n",
    "        res['correct'] += correct\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "        res['loss_arr'].append(loss.item())\n",
    "        res['correct_arr'].append(correct)\n",
    "\n",
    "        if i != 0 and i % log_interval == 0:\n",
    "            running_loss = sum(res['loss_arr'][-log_interval:])/len(res['loss_arr'][-log_interval:])\n",
    "            running_acc = sum(res['correct_arr'][-log_interval:])/(len(res['correct_arr'][-log_interval:])*batch_size)\n",
    "            avg_time = res['time']/res['counter'] * batch_size\n",
    "            tmp_counter = res['counter']\n",
    "            tmp_loss = res['loss'] / tmp_counter\n",
    "            tmp_acc = res['correct'] / tmp_counter\n",
    "            print(\">> %s \\t Epoch %d/%d \\t Batch %d/%d \\t Loss %.4f \\t Running Acc %.3f \\t Total Acc %.3f \\t Avg Batch Time %.4f\" %\n",
    "                  (partition, epoch + 1, epochs, i, loader_length, running_loss, running_acc, tmp_acc, avg_time))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    if partition == 'test':\n",
    "        res['label'] = torch.cat(res['label']).unsqueeze(-1)\n",
    "        res['score'] = torch.cat(res['score'])\n",
    "        res['score'] = torch.cat((res['label'],res['score']),dim=-1)\n",
    "    res['loss'] = res['loss'] / res['counter']\n",
    "    res['acc'] = res['correct'] / res['counter']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(res):\n",
    "    ### training and validation\n",
    "    for epoch in range(0, epochs):\n",
    "        train_res = run(epoch, dataloaders['train'], partition='train')\n",
    "        print(\"Time: train: %.2f \\t Train loss %.4f \\t Train acc: %.4f\" % (train_res['time'],train_res['loss'],train_res['acc']))\n",
    "        if epoch % val_interval == 0:\n",
    "            torch.save(model.state_dict(), f\"{logdir}/checkpoint-epoch-{epoch}.pt\")\n",
    "            with torch.no_grad():\n",
    "                val_res = run(epoch, dataloaders['val'], partition='val')\n",
    "            res['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "            res['train_time'].append(train_res['time'])\n",
    "            res['val_time'].append(val_res['time'])\n",
    "            res['train_loss'].append(train_res['loss'])\n",
    "            res['train_acc'].append(train_res['acc'])\n",
    "            res['val_loss'].append(val_res['loss'])\n",
    "            res['val_acc'].append(val_res['acc'])\n",
    "            res['epochs'].append(epoch)\n",
    "\n",
    "                ## save best model\n",
    "            if val_res['acc'] > res['best_val']:\n",
    "                print(\"New best validation model, saving...\")\n",
    "                torch.save(model.state_dict(), f\"{logdir}/best-val-model.pt\")\n",
    "                res['best_val'] = val_res['acc']\n",
    "                res['best_epoch'] = epoch\n",
    "\n",
    "            print(\"Epoch %d/%d finished.\" % (epoch, epochs))\n",
    "            print(\"Train time: %.2f \\t Val time %.2f\" % (train_res['time'], val_res['time']))\n",
    "            print(\"Train loss %.4f \\t Train acc: %.4f\" % (train_res['loss'], train_res['acc']))\n",
    "            print(\"Val loss: %.4f \\t Val acc: %.4f\" % (val_res['loss'], val_res['acc']))\n",
    "            print(\"Best val acc: %.4f at epoch %d.\" % (res['best_val'],  res['best_epoch']))\n",
    "\n",
    "            \n",
    "\n",
    "        ## adjust learning rate\n",
    "        if (epoch < 31):\n",
    "            lr_scheduler.step(metrics=val_res['acc'])\n",
    "        else:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr']*0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(res):\n",
    "    ### test on best model\n",
    "    best_model = torch.load(f\"{logdir}/checkpoint-epoch-9.pt\", map_location=device)\n",
    "    model.load_state_dict(best_model)\n",
    "    with torch.no_grad():\n",
    "        test_res = run(0, dataloaders['test'], partition='test')\n",
    "\n",
    "    print(\"Test: Loss %.4f \\t Acc %.4f\"\n",
    "          % (test_res['loss'], test_res['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize cuda\n",
    "# dist.init_process_group(backend='nccl')\n",
    "device = torch.device(\"cuda:{}\".format(0))\n",
    "dtype = torch.float32\n",
    "\n",
    "    ### load data\n",
    "dataloaders = dataset.retrieve_dataloaders(\n",
    "    200,\n",
    "    num_data=1000_000,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Size: 224072\n",
      " train samples: 800000\n",
      " val samples: 100000\n",
      " test samples: 100000\n"
     ]
    }
   ],
   "source": [
    "### create parallel model\n",
    "model = LorentzNet(n_scalar = 2, n_hidden = 72, n_class = 2,\n",
    "                   dropout = 0.2, n_layers = 6,\n",
    "                   c_weight = 0.001)\n",
    "model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "model = model.to(device)\n",
    "\n",
    "### print model and dataset information\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Network Size:\", pytorch_total_params)\n",
    "for (split, dataloader) in dataloaders.items():\n",
    "    print(f\" {split} samples: {len(dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "### lr scheduler\n",
    "base_scheduler = CosineAnnealingWarmRestarts(optimizer, 4, 2, verbose = False)\n",
    "lr_scheduler = utils.GradualWarmupScheduler(optimizer, multiplier=1,\n",
    "                                            warmup_epoch=2,\n",
    "                                            after_scheduler=base_scheduler) ## warmup\n",
    "\n",
    "### loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "### initialize logs\n",
    "res = {'epochs': [], 'lr' : [],\n",
    "       'train_time': [], 'val_time': [],  'train_loss': [], 'val_loss': [],\n",
    "       'train_acc': [], 'val_acc': [], 'best_val': 0, 'best_epoch': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 1/10 \t Batch 100/4000 \t Loss 0.4916 \t Running Acc 0.778 \t Total Acc 0.776 \t Avg Batch Time 0.2052\n",
      ">> train \t Epoch 1/10 \t Batch 200/4000 \t Loss 0.4627 \t Running Acc 0.787 \t Total Acc 0.781 \t Avg Batch Time 0.2003\n",
      ">> train \t Epoch 1/10 \t Batch 300/4000 \t Loss 0.4592 \t Running Acc 0.791 \t Total Acc 0.785 \t Avg Batch Time 0.1995\n",
      ">> train \t Epoch 1/10 \t Batch 400/4000 \t Loss 0.4626 \t Running Acc 0.789 \t Total Acc 0.786 \t Avg Batch Time 0.1993\n",
      ">> train \t Epoch 1/10 \t Batch 500/4000 \t Loss 0.4596 \t Running Acc 0.788 \t Total Acc 0.786 \t Avg Batch Time 0.1995\n",
      ">> train \t Epoch 1/10 \t Batch 600/4000 \t Loss 0.4475 \t Running Acc 0.794 \t Total Acc 0.788 \t Avg Batch Time 0.1997\n",
      ">> train \t Epoch 1/10 \t Batch 700/4000 \t Loss 0.4554 \t Running Acc 0.790 \t Total Acc 0.788 \t Avg Batch Time 0.1999\n",
      ">> train \t Epoch 1/10 \t Batch 800/4000 \t Loss 0.4509 \t Running Acc 0.793 \t Total Acc 0.789 \t Avg Batch Time 0.2005\n",
      ">> train \t Epoch 1/10 \t Batch 900/4000 \t Loss 0.4415 \t Running Acc 0.798 \t Total Acc 0.790 \t Avg Batch Time 0.2008\n",
      ">> train \t Epoch 1/10 \t Batch 1000/4000 \t Loss 0.4459 \t Running Acc 0.795 \t Total Acc 0.790 \t Avg Batch Time 0.2013\n",
      ">> train \t Epoch 1/10 \t Batch 1100/4000 \t Loss 0.4464 \t Running Acc 0.796 \t Total Acc 0.791 \t Avg Batch Time 0.2020\n",
      ">> train \t Epoch 1/10 \t Batch 1200/4000 \t Loss 0.4486 \t Running Acc 0.798 \t Total Acc 0.791 \t Avg Batch Time 0.2027\n",
      ">> train \t Epoch 1/10 \t Batch 1300/4000 \t Loss 0.4433 \t Running Acc 0.797 \t Total Acc 0.792 \t Avg Batch Time 0.2030\n",
      ">> train \t Epoch 1/10 \t Batch 1400/4000 \t Loss 0.4455 \t Running Acc 0.795 \t Total Acc 0.792 \t Avg Batch Time 0.2034\n",
      ">> train \t Epoch 1/10 \t Batch 1500/4000 \t Loss 0.4407 \t Running Acc 0.802 \t Total Acc 0.793 \t Avg Batch Time 0.2036\n",
      ">> train \t Epoch 1/10 \t Batch 1600/4000 \t Loss 0.4458 \t Running Acc 0.796 \t Total Acc 0.793 \t Avg Batch Time 0.2041\n",
      ">> train \t Epoch 1/10 \t Batch 1700/4000 \t Loss 0.4428 \t Running Acc 0.799 \t Total Acc 0.793 \t Avg Batch Time 0.2044\n",
      ">> train \t Epoch 1/10 \t Batch 1800/4000 \t Loss 0.4435 \t Running Acc 0.799 \t Total Acc 0.794 \t Avg Batch Time 0.2047\n",
      ">> train \t Epoch 1/10 \t Batch 1900/4000 \t Loss 0.4450 \t Running Acc 0.799 \t Total Acc 0.794 \t Avg Batch Time 0.2049\n",
      ">> train \t Epoch 1/10 \t Batch 2000/4000 \t Loss 0.4405 \t Running Acc 0.800 \t Total Acc 0.794 \t Avg Batch Time 0.2052\n",
      ">> train \t Epoch 1/10 \t Batch 2100/4000 \t Loss 0.4465 \t Running Acc 0.796 \t Total Acc 0.794 \t Avg Batch Time 0.2055\n",
      ">> train \t Epoch 1/10 \t Batch 2200/4000 \t Loss 0.4488 \t Running Acc 0.797 \t Total Acc 0.794 \t Avg Batch Time 0.2057\n",
      ">> train \t Epoch 1/10 \t Batch 2300/4000 \t Loss 0.4382 \t Running Acc 0.800 \t Total Acc 0.795 \t Avg Batch Time 0.2059\n",
      ">> train \t Epoch 1/10 \t Batch 2400/4000 \t Loss 0.4337 \t Running Acc 0.805 \t Total Acc 0.795 \t Avg Batch Time 0.2061\n",
      ">> train \t Epoch 1/10 \t Batch 2500/4000 \t Loss 0.4381 \t Running Acc 0.803 \t Total Acc 0.795 \t Avg Batch Time 0.2062\n",
      ">> train \t Epoch 1/10 \t Batch 2600/4000 \t Loss 0.4365 \t Running Acc 0.801 \t Total Acc 0.796 \t Avg Batch Time 0.2063\n",
      ">> train \t Epoch 1/10 \t Batch 2700/4000 \t Loss 0.4396 \t Running Acc 0.796 \t Total Acc 0.796 \t Avg Batch Time 0.2065\n",
      ">> train \t Epoch 1/10 \t Batch 2800/4000 \t Loss 0.4372 \t Running Acc 0.798 \t Total Acc 0.796 \t Avg Batch Time 0.2067\n",
      ">> train \t Epoch 1/10 \t Batch 2900/4000 \t Loss 0.4375 \t Running Acc 0.801 \t Total Acc 0.796 \t Avg Batch Time 0.2068\n",
      ">> train \t Epoch 1/10 \t Batch 3000/4000 \t Loss 0.4402 \t Running Acc 0.800 \t Total Acc 0.796 \t Avg Batch Time 0.2069\n",
      ">> train \t Epoch 1/10 \t Batch 3100/4000 \t Loss 0.4403 \t Running Acc 0.802 \t Total Acc 0.796 \t Avg Batch Time 0.2071\n",
      ">> train \t Epoch 1/10 \t Batch 3200/4000 \t Loss 0.4398 \t Running Acc 0.799 \t Total Acc 0.796 \t Avg Batch Time 0.2072\n",
      ">> train \t Epoch 1/10 \t Batch 3300/4000 \t Loss 0.4415 \t Running Acc 0.799 \t Total Acc 0.796 \t Avg Batch Time 0.2073\n",
      ">> train \t Epoch 1/10 \t Batch 3400/4000 \t Loss 0.4303 \t Running Acc 0.805 \t Total Acc 0.797 \t Avg Batch Time 0.2074\n",
      ">> train \t Epoch 1/10 \t Batch 3500/4000 \t Loss 0.4435 \t Running Acc 0.793 \t Total Acc 0.796 \t Avg Batch Time 0.2075\n",
      ">> train \t Epoch 1/10 \t Batch 3600/4000 \t Loss 0.4408 \t Running Acc 0.800 \t Total Acc 0.797 \t Avg Batch Time 0.2076\n",
      ">> train \t Epoch 1/10 \t Batch 3700/4000 \t Loss 0.4405 \t Running Acc 0.797 \t Total Acc 0.797 \t Avg Batch Time 0.2077\n",
      ">> train \t Epoch 1/10 \t Batch 3800/4000 \t Loss 0.4342 \t Running Acc 0.804 \t Total Acc 0.797 \t Avg Batch Time 0.2078\n",
      ">> train \t Epoch 1/10 \t Batch 3900/4000 \t Loss 0.4380 \t Running Acc 0.801 \t Total Acc 0.797 \t Avg Batch Time 0.2079\n",
      "Time: train: 831.90 \t Train loss 0.4451 \t Train acc: 0.7970\n",
      ">> val \t Epoch 1/10 \t Batch 100/500 \t Loss 0.4630 \t Running Acc 0.796 \t Total Acc 0.796 \t Avg Batch Time 0.0906\n",
      ">> val \t Epoch 1/10 \t Batch 200/500 \t Loss 0.4648 \t Running Acc 0.799 \t Total Acc 0.798 \t Avg Batch Time 0.0886\n",
      ">> val \t Epoch 1/10 \t Batch 300/500 \t Loss 0.4868 \t Running Acc 0.787 \t Total Acc 0.794 \t Avg Batch Time 0.0878\n",
      ">> val \t Epoch 1/10 \t Batch 400/500 \t Loss 0.4760 \t Running Acc 0.790 \t Total Acc 0.793 \t Avg Batch Time 0.0873\n",
      "New best validation model, saving...\n",
      "Epoch 0/10 finished.\n",
      "Train time: 831.90 \t Val time 43.45\n",
      "Train loss 0.4451 \t Train acc: 0.7970\n",
      "Val loss: 0.4723 \t Val acc: 0.7927\n",
      "Best val acc: 0.7927 at epoch 0.\n",
      ">> train \t Epoch 2/10 \t Batch 100/4000 \t Loss 0.4394 \t Running Acc 0.801 \t Total Acc 0.801 \t Avg Batch Time 0.2119\n",
      ">> train \t Epoch 2/10 \t Batch 200/4000 \t Loss 0.4380 \t Running Acc 0.802 \t Total Acc 0.801 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 300/4000 \t Loss 0.4407 \t Running Acc 0.802 \t Total Acc 0.802 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 400/4000 \t Loss 0.4466 \t Running Acc 0.798 \t Total Acc 0.801 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 500/4000 \t Loss 0.4441 \t Running Acc 0.799 \t Total Acc 0.801 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 600/4000 \t Loss 0.4334 \t Running Acc 0.802 \t Total Acc 0.801 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 2/10 \t Batch 700/4000 \t Loss 0.4426 \t Running Acc 0.800 \t Total Acc 0.801 \t Avg Batch Time 0.2113\n",
      ">> train \t Epoch 2/10 \t Batch 800/4000 \t Loss 0.4398 \t Running Acc 0.801 \t Total Acc 0.801 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 2/10 \t Batch 900/4000 \t Loss 0.4336 \t Running Acc 0.806 \t Total Acc 0.801 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 1000/4000 \t Loss 0.4364 \t Running Acc 0.802 \t Total Acc 0.801 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 1100/4000 \t Loss 0.4364 \t Running Acc 0.804 \t Total Acc 0.802 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 1200/4000 \t Loss 0.4367 \t Running Acc 0.805 \t Total Acc 0.802 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 2/10 \t Batch 1300/4000 \t Loss 0.4354 \t Running Acc 0.801 \t Total Acc 0.802 \t Avg Batch Time 0.2113\n",
      ">> train \t Epoch 2/10 \t Batch 1400/4000 \t Loss 0.4326 \t Running Acc 0.803 \t Total Acc 0.802 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 1500/4000 \t Loss 0.4313 \t Running Acc 0.808 \t Total Acc 0.802 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 1600/4000 \t Loss 0.4380 \t Running Acc 0.803 \t Total Acc 0.802 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 1700/4000 \t Loss 0.4352 \t Running Acc 0.803 \t Total Acc 0.802 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 1800/4000 \t Loss 0.4317 \t Running Acc 0.805 \t Total Acc 0.803 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 1900/4000 \t Loss 0.4379 \t Running Acc 0.804 \t Total Acc 0.803 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 2000/4000 \t Loss 0.4323 \t Running Acc 0.803 \t Total Acc 0.803 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 2100/4000 \t Loss 0.4377 \t Running Acc 0.802 \t Total Acc 0.803 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 2200/4000 \t Loss 0.4401 \t Running Acc 0.802 \t Total Acc 0.803 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 2300/4000 \t Loss 0.4279 \t Running Acc 0.808 \t Total Acc 0.803 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 2400/4000 \t Loss 0.4236 \t Running Acc 0.810 \t Total Acc 0.803 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 2/10 \t Batch 2500/4000 \t Loss 0.4282 \t Running Acc 0.806 \t Total Acc 0.803 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 2600/4000 \t Loss 0.4285 \t Running Acc 0.809 \t Total Acc 0.803 \t Avg Batch Time 0.2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 2/10 \t Batch 2700/4000 \t Loss 0.4294 \t Running Acc 0.805 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 2800/4000 \t Loss 0.4282 \t Running Acc 0.806 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 2900/4000 \t Loss 0.4289 \t Running Acc 0.808 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3000/4000 \t Loss 0.4311 \t Running Acc 0.806 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3100/4000 \t Loss 0.4313 \t Running Acc 0.806 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3200/4000 \t Loss 0.4303 \t Running Acc 0.804 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3300/4000 \t Loss 0.4336 \t Running Acc 0.806 \t Total Acc 0.804 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 2/10 \t Batch 3400/4000 \t Loss 0.4207 \t Running Acc 0.812 \t Total Acc 0.804 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 2/10 \t Batch 3500/4000 \t Loss 0.4342 \t Running Acc 0.801 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3600/4000 \t Loss 0.4332 \t Running Acc 0.806 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3700/4000 \t Loss 0.4314 \t Running Acc 0.804 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3800/4000 \t Loss 0.4235 \t Running Acc 0.811 \t Total Acc 0.804 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 2/10 \t Batch 3900/4000 \t Loss 0.4291 \t Running Acc 0.808 \t Total Acc 0.805 \t Avg Batch Time 0.2111\n",
      "Time: train: 844.39 \t Train loss 0.4335 \t Train acc: 0.8046\n",
      ">> val \t Epoch 2/10 \t Batch 100/500 \t Loss 0.4309 \t Running Acc 0.812 \t Total Acc 0.812 \t Avg Batch Time 0.0872\n",
      ">> val \t Epoch 2/10 \t Batch 200/500 \t Loss 0.4340 \t Running Acc 0.813 \t Total Acc 0.812 \t Avg Batch Time 0.0871\n",
      ">> val \t Epoch 2/10 \t Batch 300/500 \t Loss 0.4525 \t Running Acc 0.803 \t Total Acc 0.809 \t Avg Batch Time 0.0868\n",
      ">> val \t Epoch 2/10 \t Batch 400/500 \t Loss 0.4409 \t Running Acc 0.807 \t Total Acc 0.809 \t Avg Batch Time 0.0865\n",
      "New best validation model, saving...\n",
      "Epoch 1/10 finished.\n",
      "Train time: 844.39 \t Val time 43.19\n",
      "Train loss 0.4335 \t Train acc: 0.8046\n",
      "Val loss: 0.4394 \t Val acc: 0.8086\n",
      "Best val acc: 0.8086 at epoch 1.\n",
      ">> train \t Epoch 3/10 \t Batch 100/4000 \t Loss 0.4216 \t Running Acc 0.811 \t Total Acc 0.810 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 3/10 \t Batch 200/4000 \t Loss 0.4194 \t Running Acc 0.811 \t Total Acc 0.811 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 3/10 \t Batch 300/4000 \t Loss 0.4226 \t Running Acc 0.813 \t Total Acc 0.811 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 400/4000 \t Loss 0.4313 \t Running Acc 0.807 \t Total Acc 0.810 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 3/10 \t Batch 500/4000 \t Loss 0.4270 \t Running Acc 0.810 \t Total Acc 0.810 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 600/4000 \t Loss 0.4183 \t Running Acc 0.816 \t Total Acc 0.811 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 700/4000 \t Loss 0.4239 \t Running Acc 0.811 \t Total Acc 0.811 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 800/4000 \t Loss 0.4237 \t Running Acc 0.814 \t Total Acc 0.812 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 900/4000 \t Loss 0.4137 \t Running Acc 0.818 \t Total Acc 0.812 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 1000/4000 \t Loss 0.4178 \t Running Acc 0.814 \t Total Acc 0.812 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 1100/4000 \t Loss 0.4193 \t Running Acc 0.817 \t Total Acc 0.813 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 1200/4000 \t Loss 0.4201 \t Running Acc 0.814 \t Total Acc 0.813 \t Avg Batch Time 0.2113\n",
      ">> train \t Epoch 3/10 \t Batch 1300/4000 \t Loss 0.4151 \t Running Acc 0.818 \t Total Acc 0.813 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 1400/4000 \t Loss 0.4164 \t Running Acc 0.814 \t Total Acc 0.813 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 1500/4000 \t Loss 0.4108 \t Running Acc 0.821 \t Total Acc 0.814 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 1600/4000 \t Loss 0.4193 \t Running Acc 0.815 \t Total Acc 0.814 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 1700/4000 \t Loss 0.4160 \t Running Acc 0.818 \t Total Acc 0.814 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 1800/4000 \t Loss 0.4130 \t Running Acc 0.820 \t Total Acc 0.814 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 1900/4000 \t Loss 0.4171 \t Running Acc 0.816 \t Total Acc 0.815 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 2000/4000 \t Loss 0.4117 \t Running Acc 0.818 \t Total Acc 0.815 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 2100/4000 \t Loss 0.4189 \t Running Acc 0.818 \t Total Acc 0.815 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 2200/4000 \t Loss 0.4221 \t Running Acc 0.816 \t Total Acc 0.815 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 2300/4000 \t Loss 0.4088 \t Running Acc 0.816 \t Total Acc 0.815 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 3/10 \t Batch 2400/4000 \t Loss 0.4070 \t Running Acc 0.821 \t Total Acc 0.815 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 2500/4000 \t Loss 0.4071 \t Running Acc 0.822 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 2600/4000 \t Loss 0.4115 \t Running Acc 0.819 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 2700/4000 \t Loss 0.4123 \t Running Acc 0.819 \t Total Acc 0.816 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 2800/4000 \t Loss 0.4088 \t Running Acc 0.818 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 2900/4000 \t Loss 0.4119 \t Running Acc 0.822 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3000/4000 \t Loss 0.4126 \t Running Acc 0.818 \t Total Acc 0.816 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 3100/4000 \t Loss 0.4125 \t Running Acc 0.820 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3200/4000 \t Loss 0.4104 \t Running Acc 0.819 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3300/4000 \t Loss 0.4152 \t Running Acc 0.816 \t Total Acc 0.816 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 3400/4000 \t Loss 0.4022 \t Running Acc 0.825 \t Total Acc 0.817 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 3/10 \t Batch 3500/4000 \t Loss 0.4182 \t Running Acc 0.814 \t Total Acc 0.817 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3600/4000 \t Loss 0.4154 \t Running Acc 0.816 \t Total Acc 0.817 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3700/4000 \t Loss 0.4134 \t Running Acc 0.815 \t Total Acc 0.816 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3800/4000 \t Loss 0.4050 \t Running Acc 0.821 \t Total Acc 0.817 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 3/10 \t Batch 3900/4000 \t Loss 0.4094 \t Running Acc 0.820 \t Total Acc 0.817 \t Avg Batch Time 0.2111\n",
      "Time: train: 844.34 \t Train loss 0.4152 \t Train acc: 0.8168\n",
      ">> val \t Epoch 3/10 \t Batch 100/500 \t Loss 0.4043 \t Running Acc 0.825 \t Total Acc 0.825 \t Avg Batch Time 0.0871\n",
      ">> val \t Epoch 3/10 \t Batch 200/500 \t Loss 0.4046 \t Running Acc 0.824 \t Total Acc 0.825 \t Avg Batch Time 0.0871\n",
      ">> val \t Epoch 3/10 \t Batch 300/500 \t Loss 0.4215 \t Running Acc 0.815 \t Total Acc 0.822 \t Avg Batch Time 0.0867\n",
      ">> val \t Epoch 3/10 \t Batch 400/500 \t Loss 0.4134 \t Running Acc 0.820 \t Total Acc 0.821 \t Avg Batch Time 0.0865\n",
      "New best validation model, saving...\n",
      "Epoch 2/10 finished.\n",
      "Train time: 844.34 \t Val time 43.18\n",
      "Train loss 0.4152 \t Train acc: 0.8168\n",
      "Val loss: 0.4109 \t Val acc: 0.8216\n",
      "Best val acc: 0.8216 at epoch 2.\n",
      ">> train \t Epoch 4/10 \t Batch 100/4000 \t Loss 0.4023 \t Running Acc 0.823 \t Total Acc 0.823 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 4/10 \t Batch 200/4000 \t Loss 0.4002 \t Running Acc 0.826 \t Total Acc 0.824 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 300/4000 \t Loss 0.4050 \t Running Acc 0.824 \t Total Acc 0.824 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 4/10 \t Batch 400/4000 \t Loss 0.4130 \t Running Acc 0.819 \t Total Acc 0.823 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 4/10 \t Batch 500/4000 \t Loss 0.4104 \t Running Acc 0.822 \t Total Acc 0.823 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 4/10 \t Batch 600/4000 \t Loss 0.3994 \t Running Acc 0.827 \t Total Acc 0.824 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 4/10 \t Batch 700/4000 \t Loss 0.4058 \t Running Acc 0.825 \t Total Acc 0.824 \t Avg Batch Time 0.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 4/10 \t Batch 800/4000 \t Loss 0.4044 \t Running Acc 0.824 \t Total Acc 0.824 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 4/10 \t Batch 900/4000 \t Loss 0.3963 \t Running Acc 0.830 \t Total Acc 0.824 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 4/10 \t Batch 1000/4000 \t Loss 0.4031 \t Running Acc 0.820 \t Total Acc 0.824 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 4/10 \t Batch 1100/4000 \t Loss 0.4028 \t Running Acc 0.825 \t Total Acc 0.824 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 4/10 \t Batch 1200/4000 \t Loss 0.4011 \t Running Acc 0.821 \t Total Acc 0.824 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 4/10 \t Batch 1300/4000 \t Loss 0.3995 \t Running Acc 0.825 \t Total Acc 0.824 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 4/10 \t Batch 1400/4000 \t Loss 0.4005 \t Running Acc 0.825 \t Total Acc 0.824 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 4/10 \t Batch 1500/4000 \t Loss 0.3961 \t Running Acc 0.830 \t Total Acc 0.824 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 4/10 \t Batch 1600/4000 \t Loss 0.4042 \t Running Acc 0.824 \t Total Acc 0.824 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 4/10 \t Batch 1700/4000 \t Loss 0.4006 \t Running Acc 0.828 \t Total Acc 0.825 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 4/10 \t Batch 1800/4000 \t Loss 0.3982 \t Running Acc 0.828 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 1900/4000 \t Loss 0.4008 \t Running Acc 0.827 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2000/4000 \t Loss 0.3966 \t Running Acc 0.829 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2100/4000 \t Loss 0.4039 \t Running Acc 0.827 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2200/4000 \t Loss 0.4081 \t Running Acc 0.823 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2300/4000 \t Loss 0.3961 \t Running Acc 0.823 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2400/4000 \t Loss 0.3928 \t Running Acc 0.830 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 2500/4000 \t Loss 0.3947 \t Running Acc 0.832 \t Total Acc 0.825 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 2600/4000 \t Loss 0.3989 \t Running Acc 0.826 \t Total Acc 0.825 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 2700/4000 \t Loss 0.4023 \t Running Acc 0.824 \t Total Acc 0.825 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 2800/4000 \t Loss 0.3951 \t Running Acc 0.827 \t Total Acc 0.825 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 2900/4000 \t Loss 0.4009 \t Running Acc 0.827 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3000/4000 \t Loss 0.3992 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3100/4000 \t Loss 0.4024 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3200/4000 \t Loss 0.3996 \t Running Acc 0.824 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3300/4000 \t Loss 0.4013 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3400/4000 \t Loss 0.3925 \t Running Acc 0.830 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3500/4000 \t Loss 0.4084 \t Running Acc 0.821 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3600/4000 \t Loss 0.4049 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3700/4000 \t Loss 0.4025 \t Running Acc 0.823 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 4/10 \t Batch 3800/4000 \t Loss 0.3949 \t Running Acc 0.829 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 4/10 \t Batch 3900/4000 \t Loss 0.4012 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      "Time: train: 842.57 \t Train loss 0.4009 \t Train acc: 0.8256\n",
      ">> val \t Epoch 4/10 \t Batch 100/500 \t Loss 0.3921 \t Running Acc 0.830 \t Total Acc 0.830 \t Avg Batch Time 0.0869\n",
      ">> val \t Epoch 4/10 \t Batch 200/500 \t Loss 0.3921 \t Running Acc 0.832 \t Total Acc 0.831 \t Avg Batch Time 0.0867\n",
      ">> val \t Epoch 4/10 \t Batch 300/500 \t Loss 0.4057 \t Running Acc 0.823 \t Total Acc 0.828 \t Avg Batch Time 0.0866\n",
      ">> val \t Epoch 4/10 \t Batch 400/500 \t Loss 0.3997 \t Running Acc 0.825 \t Total Acc 0.827 \t Avg Batch Time 0.0864\n",
      "New best validation model, saving...\n",
      "Epoch 3/10 finished.\n",
      "Train time: 842.57 \t Val time 43.09\n",
      "Train loss 0.4009 \t Train acc: 0.8256\n",
      "Val loss: 0.3974 \t Val acc: 0.8274\n",
      "Best val acc: 0.8274 at epoch 3.\n",
      ">> train \t Epoch 5/10 \t Batch 100/4000 \t Loss 0.3938 \t Running Acc 0.829 \t Total Acc 0.829 \t Avg Batch Time 0.2098\n",
      ">> train \t Epoch 5/10 \t Batch 200/4000 \t Loss 0.3895 \t Running Acc 0.832 \t Total Acc 0.830 \t Avg Batch Time 0.2100\n",
      ">> train \t Epoch 5/10 \t Batch 300/4000 \t Loss 0.3961 \t Running Acc 0.829 \t Total Acc 0.830 \t Avg Batch Time 0.2104\n",
      ">> train \t Epoch 5/10 \t Batch 400/4000 \t Loss 0.4028 \t Running Acc 0.826 \t Total Acc 0.829 \t Avg Batch Time 0.2104\n",
      ">> train \t Epoch 5/10 \t Batch 500/4000 \t Loss 0.4017 \t Running Acc 0.826 \t Total Acc 0.828 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 600/4000 \t Loss 0.3880 \t Running Acc 0.834 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 700/4000 \t Loss 0.3952 \t Running Acc 0.829 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 800/4000 \t Loss 0.3942 \t Running Acc 0.830 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 900/4000 \t Loss 0.3873 \t Running Acc 0.834 \t Total Acc 0.830 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 1000/4000 \t Loss 0.3940 \t Running Acc 0.828 \t Total Acc 0.830 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 1100/4000 \t Loss 0.3940 \t Running Acc 0.830 \t Total Acc 0.830 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 1200/4000 \t Loss 0.3917 \t Running Acc 0.828 \t Total Acc 0.830 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 5/10 \t Batch 1300/4000 \t Loss 0.3900 \t Running Acc 0.829 \t Total Acc 0.830 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 1400/4000 \t Loss 0.3892 \t Running Acc 0.832 \t Total Acc 0.830 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 5/10 \t Batch 1500/4000 \t Loss 0.3858 \t Running Acc 0.835 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 1600/4000 \t Loss 0.3956 \t Running Acc 0.828 \t Total Acc 0.830 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 1700/4000 \t Loss 0.3931 \t Running Acc 0.831 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 1800/4000 \t Loss 0.3891 \t Running Acc 0.831 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 1900/4000 \t Loss 0.3919 \t Running Acc 0.832 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2000/4000 \t Loss 0.3869 \t Running Acc 0.832 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2100/4000 \t Loss 0.3944 \t Running Acc 0.833 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2200/4000 \t Loss 0.3982 \t Running Acc 0.828 \t Total Acc 0.830 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 2300/4000 \t Loss 0.3877 \t Running Acc 0.829 \t Total Acc 0.830 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 2400/4000 \t Loss 0.3835 \t Running Acc 0.837 \t Total Acc 0.830 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2500/4000 \t Loss 0.3848 \t Running Acc 0.837 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2600/4000 \t Loss 0.3902 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2700/4000 \t Loss 0.3940 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.2104\n",
      ">> train \t Epoch 5/10 \t Batch 2800/4000 \t Loss 0.3849 \t Running Acc 0.835 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 2900/4000 \t Loss 0.3923 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3000/4000 \t Loss 0.3903 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3100/4000 \t Loss 0.3941 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3200/4000 \t Loss 0.3912 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3300/4000 \t Loss 0.3924 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 5/10 \t Batch 3400/4000 \t Loss 0.3836 \t Running Acc 0.832 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3500/4000 \t Loss 0.3986 \t Running Acc 0.826 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3600/4000 \t Loss 0.3963 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3700/4000 \t Loss 0.3932 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 5/10 \t Batch 3800/4000 \t Loss 0.3873 \t Running Acc 0.833 \t Total Acc 0.831 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 5/10 \t Batch 3900/4000 \t Loss 0.3930 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2106\n",
      "Time: train: 842.30 \t Train loss 0.3917 \t Train acc: 0.8307\n",
      ">> val \t Epoch 5/10 \t Batch 100/500 \t Loss 0.3850 \t Running Acc 0.834 \t Total Acc 0.833 \t Avg Batch Time 0.0869\n",
      ">> val \t Epoch 5/10 \t Batch 200/500 \t Loss 0.3842 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.0867\n",
      ">> val \t Epoch 5/10 \t Batch 300/500 \t Loss 0.3975 \t Running Acc 0.827 \t Total Acc 0.832 \t Avg Batch Time 0.0866\n",
      ">> val \t Epoch 5/10 \t Batch 400/500 \t Loss 0.3921 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.0865\n",
      "New best validation model, saving...\n",
      "Epoch 4/10 finished.\n",
      "Train time: 842.30 \t Val time 43.20\n",
      "Train loss 0.3917 \t Train acc: 0.8307\n",
      "Val loss: 0.3899 \t Val acc: 0.8311\n",
      "Best val acc: 0.8311 at epoch 4.\n",
      ">> train \t Epoch 6/10 \t Batch 100/4000 \t Loss 0.3978 \t Running Acc 0.825 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 200/4000 \t Loss 0.3980 \t Running Acc 0.829 \t Total Acc 0.827 \t Avg Batch Time 0.2103\n",
      ">> train \t Epoch 6/10 \t Batch 300/4000 \t Loss 0.4042 \t Running Acc 0.827 \t Total Acc 0.827 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 6/10 \t Batch 400/4000 \t Loss 0.4108 \t Running Acc 0.820 \t Total Acc 0.825 \t Avg Batch Time 0.2104\n",
      ">> train \t Epoch 6/10 \t Batch 500/4000 \t Loss 0.4089 \t Running Acc 0.822 \t Total Acc 0.824 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 6/10 \t Batch 600/4000 \t Loss 0.3989 \t Running Acc 0.825 \t Total Acc 0.824 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 700/4000 \t Loss 0.4050 \t Running Acc 0.827 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 800/4000 \t Loss 0.4040 \t Running Acc 0.824 \t Total Acc 0.825 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 6/10 \t Batch 900/4000 \t Loss 0.3962 \t Running Acc 0.830 \t Total Acc 0.825 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 6/10 \t Batch 1000/4000 \t Loss 0.4023 \t Running Acc 0.824 \t Total Acc 0.825 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 6/10 \t Batch 1100/4000 \t Loss 0.4023 \t Running Acc 0.826 \t Total Acc 0.825 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 6/10 \t Batch 1200/4000 \t Loss 0.4007 \t Running Acc 0.823 \t Total Acc 0.825 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 6/10 \t Batch 1300/4000 \t Loss 0.3998 \t Running Acc 0.826 \t Total Acc 0.825 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 6/10 \t Batch 1400/4000 \t Loss 0.3993 \t Running Acc 0.826 \t Total Acc 0.825 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 6/10 \t Batch 1500/4000 \t Loss 0.3944 \t Running Acc 0.831 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 1600/4000 \t Loss 0.4042 \t Running Acc 0.823 \t Total Acc 0.825 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 6/10 \t Batch 1700/4000 \t Loss 0.4019 \t Running Acc 0.826 \t Total Acc 0.825 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 1800/4000 \t Loss 0.3991 \t Running Acc 0.829 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 1900/4000 \t Loss 0.4007 \t Running Acc 0.828 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2000/4000 \t Loss 0.3973 \t Running Acc 0.828 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2100/4000 \t Loss 0.4045 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2200/4000 \t Loss 0.4089 \t Running Acc 0.823 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2300/4000 \t Loss 0.3958 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2400/4000 \t Loss 0.3920 \t Running Acc 0.830 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 2500/4000 \t Loss 0.3944 \t Running Acc 0.832 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 2600/4000 \t Loss 0.4001 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 2700/4000 \t Loss 0.4016 \t Running Acc 0.824 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 2800/4000 \t Loss 0.3944 \t Running Acc 0.829 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 2900/4000 \t Loss 0.4007 \t Running Acc 0.826 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3000/4000 \t Loss 0.4001 \t Running Acc 0.827 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3100/4000 \t Loss 0.4020 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3200/4000 \t Loss 0.4002 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3300/4000 \t Loss 0.4039 \t Running Acc 0.824 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3400/4000 \t Loss 0.3928 \t Running Acc 0.830 \t Total Acc 0.826 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 6/10 \t Batch 3500/4000 \t Loss 0.4092 \t Running Acc 0.820 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 3600/4000 \t Loss 0.4039 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 3700/4000 \t Loss 0.4024 \t Running Acc 0.824 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 3800/4000 \t Loss 0.3953 \t Running Acc 0.828 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 6/10 \t Batch 3900/4000 \t Loss 0.4008 \t Running Acc 0.825 \t Total Acc 0.826 \t Avg Batch Time 0.2107\n",
      "Time: train: 842.78 \t Train loss 0.4007 \t Train acc: 0.8260\n",
      ">> val \t Epoch 6/10 \t Batch 100/500 \t Loss 0.3899 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.0870\n",
      ">> val \t Epoch 6/10 \t Batch 200/500 \t Loss 0.3906 \t Running Acc 0.833 \t Total Acc 0.832 \t Avg Batch Time 0.0869\n",
      ">> val \t Epoch 6/10 \t Batch 300/500 \t Loss 0.4050 \t Running Acc 0.822 \t Total Acc 0.829 \t Avg Batch Time 0.0868\n",
      ">> val \t Epoch 6/10 \t Batch 400/500 \t Loss 0.3983 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.0865\n",
      "Epoch 5/10 finished.\n",
      "Train time: 842.78 \t Val time 43.17\n",
      "Train loss 0.4007 \t Train acc: 0.8260\n",
      "Val loss: 0.3961 \t Val acc: 0.8284\n",
      "Best val acc: 0.8311 at epoch 4.\n",
      ">> train \t Epoch 7/10 \t Batch 100/4000 \t Loss 0.3959 \t Running Acc 0.827 \t Total Acc 0.828 \t Avg Batch Time 0.2119\n",
      ">> train \t Epoch 7/10 \t Batch 200/4000 \t Loss 0.3941 \t Running Acc 0.830 \t Total Acc 0.829 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 7/10 \t Batch 300/4000 \t Loss 0.4005 \t Running Acc 0.827 \t Total Acc 0.828 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 400/4000 \t Loss 0.4068 \t Running Acc 0.824 \t Total Acc 0.827 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 7/10 \t Batch 500/4000 \t Loss 0.4048 \t Running Acc 0.823 \t Total Acc 0.826 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 600/4000 \t Loss 0.3940 \t Running Acc 0.830 \t Total Acc 0.827 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 700/4000 \t Loss 0.4009 \t Running Acc 0.828 \t Total Acc 0.827 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 800/4000 \t Loss 0.3996 \t Running Acc 0.825 \t Total Acc 0.827 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 7/10 \t Batch 900/4000 \t Loss 0.3910 \t Running Acc 0.833 \t Total Acc 0.828 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 7/10 \t Batch 1000/4000 \t Loss 0.3969 \t Running Acc 0.825 \t Total Acc 0.827 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 7/10 \t Batch 1100/4000 \t Loss 0.3972 \t Running Acc 0.829 \t Total Acc 0.827 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 1200/4000 \t Loss 0.3960 \t Running Acc 0.826 \t Total Acc 0.827 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 7/10 \t Batch 1300/4000 \t Loss 0.3952 \t Running Acc 0.827 \t Total Acc 0.827 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 7/10 \t Batch 1400/4000 \t Loss 0.3941 \t Running Acc 0.829 \t Total Acc 0.827 \t Avg Batch Time 0.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 7/10 \t Batch 1500/4000 \t Loss 0.3895 \t Running Acc 0.834 \t Total Acc 0.828 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 7/10 \t Batch 1600/4000 \t Loss 0.3990 \t Running Acc 0.828 \t Total Acc 0.828 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 7/10 \t Batch 1700/4000 \t Loss 0.3971 \t Running Acc 0.830 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 1800/4000 \t Loss 0.3938 \t Running Acc 0.830 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 1900/4000 \t Loss 0.3960 \t Running Acc 0.830 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2000/4000 \t Loss 0.3912 \t Running Acc 0.833 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2100/4000 \t Loss 0.3995 \t Running Acc 0.829 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2200/4000 \t Loss 0.4032 \t Running Acc 0.826 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2300/4000 \t Loss 0.3902 \t Running Acc 0.830 \t Total Acc 0.828 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2400/4000 \t Loss 0.3879 \t Running Acc 0.833 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 2500/4000 \t Loss 0.3899 \t Running Acc 0.835 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 2600/4000 \t Loss 0.3938 \t Running Acc 0.830 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 2700/4000 \t Loss 0.3974 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 2800/4000 \t Loss 0.3902 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 2900/4000 \t Loss 0.3964 \t Running Acc 0.830 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3000/4000 \t Loss 0.3941 \t Running Acc 0.830 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3100/4000 \t Loss 0.3970 \t Running Acc 0.829 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3200/4000 \t Loss 0.3947 \t Running Acc 0.829 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3300/4000 \t Loss 0.3975 \t Running Acc 0.827 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3400/4000 \t Loss 0.3892 \t Running Acc 0.833 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3500/4000 \t Loss 0.4027 \t Running Acc 0.824 \t Total Acc 0.829 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 7/10 \t Batch 3600/4000 \t Loss 0.3994 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 3700/4000 \t Loss 0.3962 \t Running Acc 0.829 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 3800/4000 \t Loss 0.3915 \t Running Acc 0.832 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 7/10 \t Batch 3900/4000 \t Loss 0.3979 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      "Time: train: 843.12 \t Train loss 0.3959 \t Train acc: 0.8289\n",
      ">> val \t Epoch 7/10 \t Batch 100/500 \t Loss 0.3858 \t Running Acc 0.835 \t Total Acc 0.835 \t Avg Batch Time 0.0866\n",
      ">> val \t Epoch 7/10 \t Batch 200/500 \t Loss 0.3875 \t Running Acc 0.833 \t Total Acc 0.834 \t Avg Batch Time 0.0868\n",
      ">> val \t Epoch 7/10 \t Batch 300/500 \t Loss 0.4015 \t Running Acc 0.826 \t Total Acc 0.831 \t Avg Batch Time 0.0866\n",
      ">> val \t Epoch 7/10 \t Batch 400/500 \t Loss 0.3942 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.0866\n",
      "Epoch 6/10 finished.\n",
      "Train time: 843.12 \t Val time 43.18\n",
      "Train loss 0.3959 \t Train acc: 0.8289\n",
      "Val loss: 0.3927 \t Val acc: 0.8308\n",
      "Best val acc: 0.8311 at epoch 4.\n",
      ">> train \t Epoch 8/10 \t Batch 100/4000 \t Loss 0.3916 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 8/10 \t Batch 200/4000 \t Loss 0.3891 \t Running Acc 0.832 \t Total Acc 0.831 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 8/10 \t Batch 300/4000 \t Loss 0.3946 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 400/4000 \t Loss 0.4014 \t Running Acc 0.825 \t Total Acc 0.829 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 500/4000 \t Loss 0.3991 \t Running Acc 0.828 \t Total Acc 0.829 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 600/4000 \t Loss 0.3882 \t Running Acc 0.834 \t Total Acc 0.830 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 700/4000 \t Loss 0.3964 \t Running Acc 0.830 \t Total Acc 0.830 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 800/4000 \t Loss 0.3939 \t Running Acc 0.830 \t Total Acc 0.830 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 8/10 \t Batch 900/4000 \t Loss 0.3858 \t Running Acc 0.836 \t Total Acc 0.831 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 1000/4000 \t Loss 0.3915 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 1100/4000 \t Loss 0.3941 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 8/10 \t Batch 1200/4000 \t Loss 0.3916 \t Running Acc 0.829 \t Total Acc 0.830 \t Avg Batch Time 0.2112\n",
      ">> train \t Epoch 8/10 \t Batch 1300/4000 \t Loss 0.3906 \t Running Acc 0.832 \t Total Acc 0.830 \t Avg Batch Time 0.2111\n",
      ">> train \t Epoch 8/10 \t Batch 1400/4000 \t Loss 0.3905 \t Running Acc 0.831 \t Total Acc 0.830 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 1500/4000 \t Loss 0.3842 \t Running Acc 0.837 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 1600/4000 \t Loss 0.3939 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 8/10 \t Batch 1700/4000 \t Loss 0.3917 \t Running Acc 0.832 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 1800/4000 \t Loss 0.3890 \t Running Acc 0.834 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 1900/4000 \t Loss 0.3915 \t Running Acc 0.831 \t Total Acc 0.831 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 2000/4000 \t Loss 0.3854 \t Running Acc 0.834 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 2100/4000 \t Loss 0.3946 \t Running Acc 0.832 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 2200/4000 \t Loss 0.3990 \t Running Acc 0.829 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 2300/4000 \t Loss 0.3855 \t Running Acc 0.833 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 2400/4000 \t Loss 0.3822 \t Running Acc 0.836 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 2500/4000 \t Loss 0.3846 \t Running Acc 0.836 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 2600/4000 \t Loss 0.3903 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 2700/4000 \t Loss 0.3933 \t Running Acc 0.834 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 2800/4000 \t Loss 0.3863 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 2900/4000 \t Loss 0.3913 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 3000/4000 \t Loss 0.3899 \t Running Acc 0.834 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 3100/4000 \t Loss 0.3930 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3200/4000 \t Loss 0.3898 \t Running Acc 0.829 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3300/4000 \t Loss 0.3938 \t Running Acc 0.829 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 3400/4000 \t Loss 0.3854 \t Running Acc 0.835 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 8/10 \t Batch 3500/4000 \t Loss 0.3970 \t Running Acc 0.825 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3600/4000 \t Loss 0.3937 \t Running Acc 0.830 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3700/4000 \t Loss 0.3922 \t Running Acc 0.831 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3800/4000 \t Loss 0.3865 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 8/10 \t Batch 3900/4000 \t Loss 0.3943 \t Running Acc 0.830 \t Total Acc 0.831 \t Avg Batch Time 0.2109\n",
      "Time: train: 843.74 \t Train loss 0.3911 \t Train acc: 0.8316\n",
      ">> val \t Epoch 8/10 \t Batch 100/500 \t Loss 0.3832 \t Running Acc 0.836 \t Total Acc 0.836 \t Avg Batch Time 0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Epoch 8/10 \t Batch 200/500 \t Loss 0.3853 \t Running Acc 0.834 \t Total Acc 0.835 \t Avg Batch Time 0.0865\n",
      ">> val \t Epoch 8/10 \t Batch 300/500 \t Loss 0.3984 \t Running Acc 0.827 \t Total Acc 0.832 \t Avg Batch Time 0.0863\n",
      ">> val \t Epoch 8/10 \t Batch 400/500 \t Loss 0.3922 \t Running Acc 0.828 \t Total Acc 0.831 \t Avg Batch Time 0.0862\n",
      "Epoch 7/10 finished.\n",
      "Train time: 843.74 \t Val time 43.01\n",
      "Train loss 0.3911 \t Train acc: 0.8316\n",
      "Val loss: 0.3902 \t Val acc: 0.8310\n",
      "Best val acc: 0.8311 at epoch 4.\n",
      ">> train \t Epoch 9/10 \t Batch 100/4000 \t Loss 0.3870 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2114\n",
      ">> train \t Epoch 9/10 \t Batch 200/4000 \t Loss 0.3844 \t Running Acc 0.834 \t Total Acc 0.833 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 9/10 \t Batch 300/4000 \t Loss 0.3910 \t Running Acc 0.832 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 400/4000 \t Loss 0.3952 \t Running Acc 0.830 \t Total Acc 0.832 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 9/10 \t Batch 500/4000 \t Loss 0.3932 \t Running Acc 0.832 \t Total Acc 0.832 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 600/4000 \t Loss 0.3811 \t Running Acc 0.837 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 700/4000 \t Loss 0.3908 \t Running Acc 0.834 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 800/4000 \t Loss 0.3891 \t Running Acc 0.833 \t Total Acc 0.833 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 9/10 \t Batch 900/4000 \t Loss 0.3830 \t Running Acc 0.837 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 1000/4000 \t Loss 0.3869 \t Running Acc 0.833 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 1100/4000 \t Loss 0.3895 \t Running Acc 0.833 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 1200/4000 \t Loss 0.3856 \t Running Acc 0.831 \t Total Acc 0.833 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 9/10 \t Batch 1300/4000 \t Loss 0.3857 \t Running Acc 0.835 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 1400/4000 \t Loss 0.3857 \t Running Acc 0.834 \t Total Acc 0.833 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 9/10 \t Batch 1500/4000 \t Loss 0.3811 \t Running Acc 0.839 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 1600/4000 \t Loss 0.3880 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 9/10 \t Batch 1700/4000 \t Loss 0.3864 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 1800/4000 \t Loss 0.3849 \t Running Acc 0.836 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 1900/4000 \t Loss 0.3879 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2000/4000 \t Loss 0.3815 \t Running Acc 0.835 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2100/4000 \t Loss 0.3904 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2200/4000 \t Loss 0.3937 \t Running Acc 0.832 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2300/4000 \t Loss 0.3819 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2400/4000 \t Loss 0.3784 \t Running Acc 0.838 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2500/4000 \t Loss 0.3792 \t Running Acc 0.838 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2600/4000 \t Loss 0.3860 \t Running Acc 0.835 \t Total Acc 0.834 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 9/10 \t Batch 2700/4000 \t Loss 0.3886 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 9/10 \t Batch 2800/4000 \t Loss 0.3819 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 2900/4000 \t Loss 0.3874 \t Running Acc 0.835 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3000/4000 \t Loss 0.3841 \t Running Acc 0.836 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3100/4000 \t Loss 0.3883 \t Running Acc 0.835 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3200/4000 \t Loss 0.3855 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3300/4000 \t Loss 0.3892 \t Running Acc 0.832 \t Total Acc 0.834 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 9/10 \t Batch 3400/4000 \t Loss 0.3800 \t Running Acc 0.837 \t Total Acc 0.834 \t Avg Batch Time 0.2106\n",
      ">> train \t Epoch 9/10 \t Batch 3500/4000 \t Loss 0.3927 \t Running Acc 0.830 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3600/4000 \t Loss 0.3907 \t Running Acc 0.833 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3700/4000 \t Loss 0.3865 \t Running Acc 0.833 \t Total Acc 0.834 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 9/10 \t Batch 3800/4000 \t Loss 0.3837 \t Running Acc 0.835 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 9/10 \t Batch 3900/4000 \t Loss 0.3891 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.2107\n",
      "Time: train: 842.99 \t Train loss 0.3865 \t Train acc: 0.8343\n",
      ">> val \t Epoch 9/10 \t Batch 100/500 \t Loss 0.3851 \t Running Acc 0.835 \t Total Acc 0.835 \t Avg Batch Time 0.0868\n",
      ">> val \t Epoch 9/10 \t Batch 200/500 \t Loss 0.3851 \t Running Acc 0.834 \t Total Acc 0.835 \t Avg Batch Time 0.0867\n",
      ">> val \t Epoch 9/10 \t Batch 300/500 \t Loss 0.3975 \t Running Acc 0.828 \t Total Acc 0.832 \t Avg Batch Time 0.0864\n",
      ">> val \t Epoch 9/10 \t Batch 400/500 \t Loss 0.3916 \t Running Acc 0.830 \t Total Acc 0.832 \t Avg Batch Time 0.0862\n",
      "Epoch 8/10 finished.\n",
      "Train time: 842.99 \t Val time 43.05\n",
      "Train loss 0.3865 \t Train acc: 0.8343\n",
      "Val loss: 0.3905 \t Val acc: 0.8310\n",
      "Best val acc: 0.8311 at epoch 4.\n",
      ">> train \t Epoch 10/10 \t Batch 100/4000 \t Loss 0.3824 \t Running Acc 0.835 \t Total Acc 0.835 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 200/4000 \t Loss 0.3796 \t Running Acc 0.837 \t Total Acc 0.836 \t Avg Batch Time 0.2105\n",
      ">> train \t Epoch 10/10 \t Batch 300/4000 \t Loss 0.3862 \t Running Acc 0.834 \t Total Acc 0.835 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 400/4000 \t Loss 0.3904 \t Running Acc 0.835 \t Total Acc 0.835 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 500/4000 \t Loss 0.3894 \t Running Acc 0.835 \t Total Acc 0.835 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 600/4000 \t Loss 0.3776 \t Running Acc 0.841 \t Total Acc 0.836 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 10/10 \t Batch 700/4000 \t Loss 0.3871 \t Running Acc 0.837 \t Total Acc 0.836 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 10/10 \t Batch 800/4000 \t Loss 0.3840 \t Running Acc 0.837 \t Total Acc 0.836 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 10/10 \t Batch 900/4000 \t Loss 0.3787 \t Running Acc 0.840 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 1000/4000 \t Loss 0.3834 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 1100/4000 \t Loss 0.3857 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 10/10 \t Batch 1200/4000 \t Loss 0.3804 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2110\n",
      ">> train \t Epoch 10/10 \t Batch 1300/4000 \t Loss 0.3810 \t Running Acc 0.838 \t Total Acc 0.837 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 10/10 \t Batch 1400/4000 \t Loss 0.3820 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2109\n",
      ">> train \t Epoch 10/10 \t Batch 1500/4000 \t Loss 0.3764 \t Running Acc 0.840 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 1600/4000 \t Loss 0.3840 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 1700/4000 \t Loss 0.3827 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 1800/4000 \t Loss 0.3815 \t Running Acc 0.838 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 1900/4000 \t Loss 0.3837 \t Running Acc 0.835 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2000/4000 \t Loss 0.3758 \t Running Acc 0.840 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 2100/4000 \t Loss 0.3866 \t Running Acc 0.839 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 2200/4000 \t Loss 0.3894 \t Running Acc 0.835 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 10/10 \t Batch 2300/4000 \t Loss 0.3776 \t Running Acc 0.835 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 2400/4000 \t Loss 0.3729 \t Running Acc 0.841 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2500/4000 \t Loss 0.3769 \t Running Acc 0.841 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2600/4000 \t Loss 0.3820 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2700/4000 \t Loss 0.3856 \t Running Acc 0.835 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2800/4000 \t Loss 0.3771 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 2900/4000 \t Loss 0.3835 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3000/4000 \t Loss 0.3802 \t Running Acc 0.838 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3100/4000 \t Loss 0.3837 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3200/4000 \t Loss 0.3812 \t Running Acc 0.836 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3300/4000 \t Loss 0.3848 \t Running Acc 0.835 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3400/4000 \t Loss 0.3750 \t Running Acc 0.840 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3500/4000 \t Loss 0.3883 \t Running Acc 0.833 \t Total Acc 0.837 \t Avg Batch Time 0.2107\n",
      ">> train \t Epoch 10/10 \t Batch 3600/4000 \t Loss 0.3872 \t Running Acc 0.834 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 3700/4000 \t Loss 0.3823 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 3800/4000 \t Loss 0.3792 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      ">> train \t Epoch 10/10 \t Batch 3900/4000 \t Loss 0.3856 \t Running Acc 0.837 \t Total Acc 0.837 \t Avg Batch Time 0.2108\n",
      "Time: train: 843.18 \t Train loss 0.3823 \t Train acc: 0.8369\n",
      ">> val \t Epoch 10/10 \t Batch 100/500 \t Loss 0.3824 \t Running Acc 0.836 \t Total Acc 0.836 \t Avg Batch Time 0.0870\n",
      ">> val \t Epoch 10/10 \t Batch 200/500 \t Loss 0.3820 \t Running Acc 0.836 \t Total Acc 0.836 \t Avg Batch Time 0.0869\n",
      ">> val \t Epoch 10/10 \t Batch 300/500 \t Loss 0.3933 \t Running Acc 0.831 \t Total Acc 0.834 \t Avg Batch Time 0.0866\n",
      ">> val \t Epoch 10/10 \t Batch 400/500 \t Loss 0.3886 \t Running Acc 0.832 \t Total Acc 0.834 \t Avg Batch Time 0.0864\n",
      "New best validation model, saving...\n",
      "Epoch 9/10 finished.\n",
      "Train time: 843.18 \t Val time 43.17\n",
      "Train loss 0.3823 \t Train acc: 0.8369\n",
      "Val loss: 0.3874 \t Val acc: 0.8333\n",
      "Best val acc: 0.8333 at epoch 9.\n"
     ]
    }
   ],
   "source": [
    "train(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test \t Epoch 1/10 \t Batch 100/500 \t Loss 0.3854 \t Running Acc 0.834 \t Total Acc 0.834 \t Avg Batch Time 0.0900\n",
      ">> test \t Epoch 1/10 \t Batch 200/500 \t Loss 0.3760 \t Running Acc 0.841 \t Total Acc 0.837 \t Avg Batch Time 0.0879\n",
      ">> test \t Epoch 1/10 \t Batch 300/500 \t Loss 0.3910 \t Running Acc 0.833 \t Total Acc 0.836 \t Avg Batch Time 0.0870\n",
      ">> test \t Epoch 1/10 \t Batch 400/500 \t Loss 0.3903 \t Running Acc 0.834 \t Total Acc 0.835 \t Avg Batch Time 0.0868\n",
      "Test: Loss 0.3858 \t Acc 0.8355\n"
     ]
    }
   ],
   "source": [
    "test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
